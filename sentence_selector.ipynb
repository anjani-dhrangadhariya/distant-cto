{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjani/anaconda3/envs/systreviewclassifi/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import operator\n",
    "import string\n",
    "\n",
    "# scikit learn imports\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import scale, StandardScaler, Normalizer, label_binarize\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, f1_score, precision_score, recall_score, classification_report, roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import umap\n",
    "\n",
    "# Natural Language Toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download()\n",
    "from nltk import ngrams, pos_tag\n",
    "\n",
    "# Libraries for imbalanced data\n",
    "# import imblearn\n",
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE, SMOTENC, SVMSMOTE\n",
    "# from imblearn.keras import BalancedBatchGenerator\n",
    "# from imblearn.pipeline import Pipeline as imbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confMatrix(y_test, y_predicted_counts):\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_predicted_counts)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plot = plot_confusion_matrix(cm, classes=['High-Grade','Low-Grade'], normalize=False, title='Confusion matrix')\n",
    "    plt.show()\n",
    "    print('the confusion matrix: ', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  4802.0\n",
      "Number of doc labels:  4782\n"
     ]
    }
   ],
   "source": [
    "# Build sentences from the EBM-NLP dataset\n",
    "\n",
    "# hilfiker\n",
    "par_text_dir_t2 = '/home/anjani/systematicReviews/data/TA_screening/hilfiker_sr_ta/PICO_annotation_project/validation_files/tokens'\n",
    "par_lab_dir_t2 = '/home/anjani/systematicReviews/data/TA_screening/hilfiker_sr_ta/PICO_annotation_project/validation_files/labels/intervention/annot'\n",
    "\n",
    "# EBM-NLP training\n",
    "par_text_dir = '/home/anjani/systematicReviews/data/TA_screening/EBM_NLP/ebm_nlp_2_00/documents/train/'\n",
    "par_lab_dir = '/home/anjani/systematicReviews/data/TA_screening/EBM_NLP/ebm_nlp_2_00/annotations/aggregated/starting_spans/interventions/train/'\n",
    "\n",
    "# EBM-NLP Gold\n",
    "par_text_dir_t1 = '/home/anjani/systematicReviews/data/TA_screening/EBM_NLP/ebm_nlp_2_00/documents/test/'\n",
    "par_lab_dir_t1 = '/home/anjani/systematicReviews/data/TA_screening/EBM_NLP/ebm_nlp_2_00/annotations/aggregated/starting_spans/interventions/test/gold/'\n",
    "\n",
    "print('Number of documents: ', len([name for name in os.listdir(par_text_dir) if os.path.isfile(os.path.join(par_text_dir, name))]) /3)\n",
    "print('Number of doc labels: ', len([name for name in os.listdir(par_lab_dir) if os.path.isfile(os.path.join(par_lab_dir, name))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file = '/home/anjani/systematicReviews/data/TA_screening/EBM_NLP/allSentence_annot/hilfiker_sentence_annotation2POS.txt'\n",
    "\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "import nltk, json\n",
    "\n",
    "def getData(par_text_dir, par_lab_dir):\n",
    "    all_text_files = os.listdir(par_text_dir)\n",
    "\n",
    "    sentences_wwo_intervention = 0\n",
    "    sentences_with_intervention = 0\n",
    "    sentences_without_intervention = 0\n",
    "\n",
    "    sent_w_intannot = []\n",
    "    sent_w_intannotLab = []\n",
    "    sent_wo_intannot = []\n",
    "    sent_wo_intannotLab = []\n",
    "\n",
    "    for i, eachFile in enumerate(all_text_files):\n",
    "        if '.tokens' in eachFile or '.txt' in eachFile and '1530836' not in eachFile:\n",
    "\n",
    "            document = os.path.join(par_text_dir, eachFile)\n",
    "            if '.tokens' in eachFile:\n",
    "                label_extension = '.AGGREGATED.ann'\n",
    "                label = os.path.join(par_lab_dir, str(eachFile).replace('.tokens', label_extension))\n",
    "            else:\n",
    "                label_extension = '.txt'\n",
    "                label = os.path.join(par_lab_dir, str(eachFile).replace('.txt', label_extension))\n",
    "\n",
    "            added_length = 0\n",
    "            if os.path.isfile(label):\n",
    "\n",
    "                write_document = dict()\n",
    "                token_list = []\n",
    "                label_list = []\n",
    "                with open(label, 'r') as labfile, open(document, 'r') as docfile:\n",
    "                    for eachToken, eachTokLabel in zip(docfile, labfile):\n",
    "                        string2print = eachToken.rstrip() + ' : ' + eachTokLabel.rstrip()\n",
    "\n",
    "                        token_list.append(eachToken.rstrip())\n",
    "                        label_list.append(eachTokLabel.rstrip())                    \n",
    "\n",
    "                s = nltk.sent_tokenize(' '.join(token_list)) # converts tokens into sentences\n",
    "                reSent = ' '.join(s) # joins the sentences into a passage\n",
    "                retokens = reSent.split(' ')\n",
    "                assert len(token_list) == len(label_list) == len(retokens)\n",
    "\n",
    "                reformed = []\n",
    "\n",
    "                write_sentences = dict()\n",
    "                for j, eachSentence in enumerate(s):\n",
    "                    words = eachSentence.split(' ')\n",
    "                    reformed.extend( words )\n",
    "\n",
    "                    fetchLab = len(words)\n",
    "                    sent_lab = label_list[added_length : added_length + fetchLab]          \n",
    "\n",
    "                    added_length = added_length + fetchLab\n",
    "                    if all(p == '0' for p in sent_lab) is False:\n",
    "                        #print(words)\n",
    "                        write_sentences[str(j)] = [words, sent_lab, [eachTuple[1]  for eachTuple in nltk.pos_tag_sents([words])[0]]]\n",
    "                        sentences_with_intervention = sentences_with_intervention + 1\n",
    "                        # Remove stopwords and punctuations from the input sentence\n",
    "                        filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "                        words2string = ' '.join(filtered_words).lower()\n",
    "                        removePunct = words2string.translate(str.maketrans('', '', string.punctuation))\n",
    "                        sent_w_intannot.append( removePunct )\n",
    "                        sent_w_intannotLab.append( 1 )\n",
    "                    else:\n",
    "                        #print('No intervention: ' , words)\n",
    "                        # writes even if no annotations are found in the sentence\n",
    "                        write_sentences[str(j)] = [words, sent_lab, [eachTuple[1]  for eachTuple in nltk.pos_tag_sents([words])[0]]]\n",
    "                        sentences_without_intervention = sentences_without_intervention + 1\n",
    "                        filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "                        words2string = ' '.join(filtered_words).lower()\n",
    "                        removePunct = words2string.translate(str.maketrans('', '', string.punctuation))\n",
    "                        sent_wo_intannot.append( removePunct )\n",
    "                        sent_wo_intannotLab.append( 0 )\n",
    "\n",
    "                    sentences_wwo_intervention = sentences_wwo_intervention + 1\n",
    "\n",
    "                assert len(token_list) == len(reformed)\n",
    "                write_document[eachFile] = write_sentences\n",
    "\n",
    "                #with open(write_file, 'a+') as writeAnnotfile:\n",
    "                    #print(write_document)\n",
    "                    #json_str = json.dumps(write_document)\n",
    "                    #writeAnnotfile.write(str(json_str))\n",
    "                    #writeAnnotfile.write('\\n')\n",
    "                #print('--------------------------------------------------------')\n",
    "    print('Number of sentences with and without intervention annotation: ' , sentences_wwo_intervention)\n",
    "    print('Number of sentences with intervention annotation: ' , sentences_with_intervention)\n",
    "    print('Number of sentences without intervention annotation: ' , sentences_without_intervention)\n",
    "    \n",
    "    return sent_w_intannot, sent_w_intannotLab, sent_wo_intannot, sent_wo_intannotLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences with and without intervention annotation:  51577\n",
      "Number of sentences with intervention annotation:  23241\n",
      "Number of sentences without intervention annotation:  28336\n"
     ]
    }
   ],
   "source": [
    "# Get training data\n",
    "sent_w_intannot, sent_w_intannotLab, sent_wo_intannot, sent_wo_intannotLab = getData(par_text_dir, par_lab_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences with and without intervention annotation:  2068\n",
      "Number of sentences with intervention annotation:  1107\n",
      "Number of sentences without intervention annotation:  961\n"
     ]
    }
   ],
   "source": [
    "# Get test data\n",
    "sent_w_intannot_t1, sent_w_intannotLab_t1, sent_wo_intannot_t1, sent_wo_intannotLab_t1 = getData(par_text_dir_t1, par_lab_dir_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences with and without intervention annotation:  2080\n",
      "Number of sentences with intervention annotation:  856\n",
      "Number of sentences without intervention annotation:  1224\n"
     ]
    }
   ],
   "source": [
    "sent_w_intannot_t2, sent_w_intannotLab_t2, sent_wo_intannot_t2, sent_wo_intannotLab_t2 = getData(par_text_dir_t2, par_lab_dir_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51577\n",
      "51577\n"
     ]
    }
   ],
   "source": [
    "# Get training dataframe\n",
    "sentsX = sent_w_intannot + sent_wo_intannot\n",
    "sentsy = sent_w_intannotLab + sent_wo_intannotLab\n",
    "print(len(sentsX))\n",
    "print(len(sentsy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2068\n",
      "2068\n"
     ]
    }
   ],
   "source": [
    "# Get test dataframe\n",
    "sentsXtest = sent_w_intannot_t1 + sent_wo_intannot_t1\n",
    "sentsytest = sent_w_intannotLab_t1 + sent_wo_intannotLab_t1\n",
    "print(len(sentsXtest))\n",
    "print(len(sentsytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080\n",
      "2080\n"
     ]
    }
   ],
   "source": [
    "# Get test dataframe\n",
    "sentsXtest2 = sent_w_intannot_t2 + sent_wo_intannot_t2\n",
    "sentsytest2 = sent_w_intannotLab_t2 + sent_wo_intannotLab_t2\n",
    "print(len(sentsXtest2))\n",
    "print(len(sentsytest2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vocabulary for the training set\n",
      "Generating vocabulary for the test set 1\n",
      "Generating vocabulary for the test set 2\n",
      "Size of vocabulary:  42376\n"
     ]
    }
   ],
   "source": [
    "# Construct the vocab from all the dataframes and remove all the words that are represented less than 10 times in the entire corpus\n",
    "\n",
    "vocabulary = dict()\n",
    "\n",
    "print('Generating vocabulary for the training set')\n",
    "for eachText in sentsX:\n",
    "    \n",
    "    eachText = eachText.split(' ')\n",
    "\n",
    "    # generate the vocabulary\n",
    "    for t in eachText:\n",
    "        if t not in vocabulary:\n",
    "            vocabulary[t] = 1\n",
    "        elif t in vocabulary:\n",
    "            vocabulary[t] = vocabulary[t] + 1\n",
    "\n",
    "print('Generating vocabulary for the test set 1')\n",
    "for eachText in sentsXtest:\n",
    "    \n",
    "    eachText = eachText.split(' ')\n",
    "\n",
    "    # generate the vocabulary\n",
    "    for t in eachText:\n",
    "        if t not in vocabulary:\n",
    "            vocabulary[t] = 1\n",
    "        elif t in vocabulary:\n",
    "            vocabulary[t] = vocabulary[t] + 1\n",
    "\n",
    "print('Generating vocabulary for the test set 2')\n",
    "for eachText in sentsXtest2:\n",
    "    \n",
    "    eachText = eachText.split(' ')\n",
    "\n",
    "    # generate the vocabulary\n",
    "    for t in eachText:\n",
    "        if t not in vocabulary:\n",
    "            vocabulary[t] = 1\n",
    "        elif t in vocabulary:\n",
    "            vocabulary[t] = vocabulary[t] + 1\n",
    "            \n",
    "print('Size of vocabulary: ', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce tokens in test set 1\n"
     ]
    }
   ],
   "source": [
    "# Remove tokens that do not appear more than 10 times in the entire corpus\n",
    "sentsXtest_reduced = [ ]\n",
    "\n",
    "print('Reduce tokens in test set 1')\n",
    "for eachText in sentsXtest:\n",
    "    \n",
    "    text_i = eachText.split(' ')\n",
    "    sample_i = [ ]\n",
    "    for t in text_i:\n",
    "        if vocabulary[t] > 10:\n",
    "            sample_i.append( t )\n",
    "    sentsXtest_reduced.append( ' '.join(sample_i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce tokens in test set 2\n"
     ]
    }
   ],
   "source": [
    "sentsXtest2_reduced = [ ]\n",
    "\n",
    "print('Reduce tokens in test set 2')\n",
    "for eachText in sentsXtest2:\n",
    "    \n",
    "    text_i = eachText.split(' ')\n",
    "    sample_i = [ ]\n",
    "    for t in text_i:\n",
    "        if vocabulary[t] > 10:\n",
    "            sample_i.append( t )\n",
    "    sentsXtest2_reduced.append( ' '.join(sample_i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce tokens in training set\n"
     ]
    }
   ],
   "source": [
    "sentsX_reduced = [ ]\n",
    "print('Reduce tokens in training set')\n",
    "for eachText in sentsX:\n",
    "    \n",
    "    text_i = eachText.split(' ')\n",
    "    sample_i = [ ]\n",
    "    for t in text_i:\n",
    "        if vocabulary[t] > 10:\n",
    "            sample_i.append( t )\n",
    "    sentsX_reduced.append( ' '.join(sample_i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sentsX) == len(sentsX_reduced) \n",
    "assert len(sentsXtest) == len(sentsXtest_reduced) == len(sentsytest)\n",
    "assert len(sentsXtest2) == len(sentsXtest2_reduced) == len(sentsytest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7648\n"
     ]
    }
   ],
   "source": [
    "vocabulary_reduced = {key:val for key, val in vocabulary.items() if val > 10}\n",
    "print(len(vocabulary_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with training set:  51577\n",
      "Dataframe with training set:  2068\n",
      "Dataframe with training set:  2080\n"
     ]
    }
   ],
   "source": [
    "df_data = pd.DataFrame(\n",
    "    {'text': sentsX_reduced,\n",
    "     'category': sentsy\n",
    "    })\n",
    "\n",
    "print('Dataframe with training set: ', len(df_data))\n",
    "\n",
    "df_testdata = pd.DataFrame(\n",
    "    {'text': sentsXtest_reduced,\n",
    "     'category': sentsytest\n",
    "    })\n",
    "\n",
    "print('Dataframe with training set: ', len(df_testdata))\n",
    "\n",
    "\n",
    "df_testdata2 = pd.DataFrame(\n",
    "    {'text': sentsXtest2_reduced,\n",
    "     'category': sentsytest2\n",
    "    })\n",
    "\n",
    "print('Dataframe with training set: ', len(df_testdata2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reports with the intervention annotation:  23241\n",
      "Number of reports without the intervention annotation:  28336\n"
     ]
    }
   ],
   "source": [
    "print('Number of reports with the intervention annotation: ', list(df_data['category']).count(1))\n",
    "print('Number of reports without the intervention annotation: ', list(df_data['category']).count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Number of sentences with and without intervention annotation.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df_data.category)\n",
    "plt.xlabel('Label')\n",
    "plt.title('Number of sentences with and without intervention annotation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Experiments (tf-idf, no oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_grids(s):\n",
    "    \n",
    "    if 'logistic_regression' in s:\n",
    "        \n",
    "        param_grid = [{'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "                      'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                      'vect__max_df': [0.7, 0.8, 0.9],\n",
    "                      'vect__min_df': [0.0, 0.1, 0.2, 0.3],\n",
    "                      'vect__norm': ['l1','l2'],\n",
    "                      'clf__penalty': ['l1','l2'],\n",
    "                      'clf__class_weight': ['balanced', None]\n",
    "              }\n",
    "             ]\n",
    "          \n",
    "        return param_grid\n",
    "    \n",
    "    if 'svm' in s:      \n",
    "  \n",
    "        param_grid = [{'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "                       'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                       'vect__max_df': [0.7, 0.8, 0.9],\n",
    "                       'vect__min_df': [0.0, 0.1, 0.2, 0.3],\n",
    "                       'vect__norm': ['l1','l2']\n",
    "                      }\n",
    "                     ]\n",
    "        \n",
    "        return param_grid\n",
    "    \n",
    "    if 'knn' in s:\n",
    "        \n",
    "        param_grid = [{'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "                        'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                        'vect__max_df': [0.7, 0.8, 0.9],\n",
    "                        'vect__min_df': [0.0, 0.1, 0.2, 0.3],\n",
    "                        'vect__norm': ['l1','l2'],\n",
    "                        'clf__n_neighbors': [9, 11, 21, 31],\n",
    "                        'clf__metric': ['minkowski', 'euclidean']\n",
    "              }\n",
    "             ]\n",
    "        \n",
    "        return param_grid\n",
    "    \n",
    "    if 'trial' in s:\n",
    "        \n",
    "        param_grid = [{'clf__penalty': ['l2']\n",
    "              }\n",
    "             ]\n",
    "        \n",
    "        return param_grid\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Please correctly specify the name of algorithm to apply...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_pipeline(s):\n",
    "    \n",
    "    # Initialize vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=None, smooth_idf=True)\n",
    "    \n",
    "    if 'logistic_regression' in s:\n",
    "        \n",
    "        log_reg_clf = LogisticRegression(intercept_scaling=1, random_state=42)\n",
    "        log_reg_clf_tfidf = Pipeline([('vect', tfidf_vectorizer), ('scaler', normalizer), ('clf', log_reg_clf)])\n",
    "        \n",
    "        return log_reg_clf_tfidf\n",
    "    \n",
    "    if 'svm' in s:\n",
    "        \n",
    "        svm_clf = CalibratedClassifierCV(base_estimator=LinearSVC(penalty = 'l2', class_weight = 'balanced', fit_intercept=False, random_state=42, verbose=1, dual=False))\n",
    "        svm_clf_tfidf = Pipeline([('vect', tfidf_vectorizer), ('norm', normalizer), ('clf', svm_clf)])\n",
    "        \n",
    "        return svm_clf_tfidf\n",
    "    \n",
    "    if 'knn' in s:\n",
    "        \n",
    "        knn_clf = KNeighborsClassifier(weights='uniform', algorithm='auto')\n",
    "        knn_clf_tfidf = Pipeline([('vect', tfidf_vectorizer), ('norm', normalizer), ('clf', knn_clf)])\n",
    "        \n",
    "        return knn_clf_tfidf\n",
    "    \n",
    "    if 'trial' in s:\n",
    "        \n",
    "        svm_clf = CalibratedClassifierCV(base_estimator=LinearSVC(penalty='l2', fit_intercept=False, class_weight='balanced', random_state=42, verbose=1, dual=False))\n",
    "        print(svm_clf.get_params().keys())\n",
    "        svm_clf_tfidf = Pipeline([('vect', tfidf_vectorizer), ('norm', normalizer), ('clf', svm_clf)])\n",
    "        \n",
    "        return svm_clf_tfidf\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Please correctly specify the name of algorithm to apply...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gridSearch, X_test, y_test):\n",
    "    \n",
    "    test_roc_auc = []\n",
    "    \n",
    "    precision_include = []\n",
    "    recall_include = []\n",
    "    f1_include = []\n",
    "\n",
    "    precision_exclude = []\n",
    "    recall_exclude = []\n",
    "    f1_exclude = []\n",
    "    \n",
    "    # Using best model, predict on the test set\n",
    "    print('-' * 30)\n",
    "    y_pred = gridSearch.best_estimator_.predict(X_test)\n",
    "\n",
    "    y_test = y_test.to_numpy()\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    ROCAUC_score = roc_auc_score(y_test, y_pred)\n",
    "    print('The ROC-AUC score for the test set is: ', ROCAUC_score)\n",
    "    test_roc_auc.append(ROCAUC_score)\n",
    "\n",
    "    classReport =  classification_report(y_test, y_pred)\n",
    "    print(classReport)\n",
    "\n",
    "    ## Plot confusion matrix\n",
    "    plot_confMatrix(y_test, y_pred)\n",
    "\n",
    "    prec_scr = precision_score(y_test, y_pred, average=None)\n",
    "    rec_scr = recall_score(y_test, y_pred, average=None)\n",
    "    f_scr = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "    precision_include.append(prec_scr[1])\n",
    "    recall_include.append(rec_scr[1])\n",
    "    f1_include.append(f_scr[1])\n",
    "\n",
    "    precision_exclude.append(prec_scr[0])\n",
    "    recall_exclude.append(rec_scr[0])\n",
    "    f1_exclude.append(f_scr[0])\n",
    "        \n",
    "    ## Print mean scores here\n",
    "    meanTrainPRU = sum(train_roc_auc)/len(train_roc_auc)\n",
    "    meanTestPRU = sum(test_roc_auc)/len(test_roc_auc)\n",
    "\n",
    "    print('Mean training ROC-AUC score is: ', meanTrainPRU)\n",
    "    print('Mean test ROC-AUC score is: ', meanTestPRU)\n",
    "\n",
    "    meanP = sum(precision_include)/len(precision_include)\n",
    "    meanR = sum(recall_include)/len(recall_include)\n",
    "    meanF1 = sum(f1_include)/len(f1_include)\n",
    "\n",
    "    print('Mean precision for positive sentences is: ', meanP)\n",
    "    print('Mean recall for positive sentences is: ', meanR)\n",
    "    print('Mean F1 for positive sentences is: ', meanF1)\n",
    "\n",
    "    meanP_0 = sum(precision_exclude)/len(precision_exclude)\n",
    "    meanR_0 = sum(recall_exclude)/len(recall_exclude)\n",
    "    meanF1_0 = sum(f1_exclude)/len(f1_exclude)\n",
    "\n",
    "    print('Mean precision for negative sentences is: ', meanP_0)\n",
    "    print('Mean recall for negative sentences is: ', meanR_0)\n",
    "    print('Mean F1 for negative sentences is: ', meanF1_0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_baselines(s, df_data, df_testdata, df_testdata2):\n",
    "    \n",
    "    # Shuffle the dataframes\n",
    "    df_data = df_data.sample(frac=1).reset_index(drop=True)\n",
    "    df_testdata = df_testdata.sample(frac=1).reset_index(drop=True)\n",
    "    df_testdata2 = df_testdata2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    train_roc_auc = []\n",
    "   \n",
    "    #for i in range(0, 3):\n",
    "        \n",
    "    # get training and test datasets\n",
    "    X_train, y_train = df_data['text'], df_data['category']\n",
    "    X_test1, y_test1 = df_testdata['text'], df_testdata['category']\n",
    "    X_test2, y_test2 = df_testdata2['text'], df_testdata2['category']\n",
    "\n",
    "    # get training and evaluation datasets\n",
    "    #X_train, X_eval, y_train, y_eval = train_test_split(X_train_i, y_train_i, test_size=0.20, shuffle=True, random_state=42)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Training set has ', list(y_train).count(1), ' positive instances and ', list(y_train).count(0), ' negative instances.')\n",
    "    print('Test set 1 has ', list(y_test1).count(1), ' positive instances and ', list(y_test1).count(0), ' negative instances.')\n",
    "    print('Test set 2 has ', list(y_test2).count(1), ' positive instances and ', list(y_test2).count(0), ' negative instances.')\n",
    "    print('-' * 30)\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    # Get the test fold from above split\n",
    "    #testFold = getTestFold(X_train, y_train, X_eval, y_eval)\n",
    "    #ps = PredefinedSplit(testFold)\n",
    "\n",
    "    #series_list_corpus = [X_train, X_eval]\n",
    "    #series_list_label = [y_train, y_eval]\n",
    "\n",
    "    #X_train_main = pd.concat(series_list_corpus)\n",
    "    #y_train_main = pd.concat(series_list_label)\n",
    "    #y_train_main = y_train_main.astype('int')\n",
    "\n",
    "    y_train = y_train.astype('int')\n",
    "\n",
    "    clf = get_classifier_pipeline(s)\n",
    "    params = get_param_grids(s)\n",
    "\n",
    "    gridSearch = GridSearchCV(clf, params, scoring='roc_auc', cv=3, verbose=1, n_jobs=-20)\n",
    "\n",
    "    #gridSearch = GridSearchCV(clf, params, scoring='roc_auc', cv=ps, verbose=1, n_jobs=-1)\n",
    "    grid_result = gridSearch.fit(X_train, y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    train_roc_auc.append(grid_result.best_score_)\n",
    "\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, param in zip(means, params):\n",
    "        print(\"Mean ROC-AUC score: %f with: %r\" % (mean, param))       \n",
    "    \n",
    "    evaluate(gridSearch, X_test1, y_test1)\n",
    "    evaluate(gridSearch, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Executing  logistic_regression  pipeline...\n",
      "##################################################\n",
      "------------------------------\n",
      "Training set has  23241  positive instances and  28336  negative instances.\n",
      "Test set 1 has  1107  positive instances and  961  negative instances.\n",
      "Test set 2 has  856  positive instances and  1224  negative instances.\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 1536 candidates, totalling 4608 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-20)]: Using backend LokyBackend with 29 concurrent workers.\n",
      "[Parallel(n_jobs=-20)]: Done 142 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-20)]: Done 392 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-20)]: Done 742 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-20)]: Done 1192 tasks      | elapsed:  2.5min\n",
      "/home/anjani/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "baselines = ['logistic_regression', 'svm', 'knn']\n",
    "\n",
    "for eachModel in baselines:\n",
    "    print('#' * 50)\n",
    "    print('Executing ', eachModel, ' pipeline...')\n",
    "    print('#' * 50)\n",
    "    execute_baselines(eachModel, df_data, df_testdata, df_testdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
